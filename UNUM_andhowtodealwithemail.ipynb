{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import xgboost\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplot\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalise\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = 'english'\n",
    "#NROWS_IMPORT = 300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', n_rows=NROWS_IMPORT)\n",
    "df.dropna(inplace=True, subset=['EMAIL_TEXT,'INITIAL_EMAIL_SUBJECT_LINE''])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_count = Counter(df[EMAIL_TEXT])\n",
    "common = pd.DataFrame(string_count.most_common(10000))\n",
    "\n",
    "print(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.str.count can be used to cound a number of text strings in a data frame\n",
    "#df['EMAIL_TEXT]'.str.count('fill this with a string or whatever')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(df):\n",
    "    \n",
    "    df['EMAIL_TEXT'] = df['EMAIL_TEXT'].apply(lambda x : str(x))\n",
    "    df['EMAIL_TEXT'] = df['EMAIL_TEXT'].apply(lambda x : x.lower())\n",
    "    df['EMAIL_TEXT'] = df['EMAIL_TEXT'].str.replace('\\n','').str.replace('\\r','')\n",
    "    df['EMAIL_TEXT_CLEAN'] = df['EMAIL_TEXT'].apply(lambda x : x.replace(\"literally any string you can put in here and copy it over and over\",\"\"))\n",
    "                                                                .replace(\"fill this in again with literally anything\",\"\")\n",
    "        \n",
    "    df['EMAIL_TEXT_CLEAN'] = df['EMAIL_TEXT_CLEAN'].apply(lambda text: gensim.utils.simple_preprocess(text))\n",
    "    df['EMAIL_TEXT_CLEAN'] = df['EMAIL_TEXT_CLEAN'].apply(lambda text: ' '.join(text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "df.EMAIL_TEXT_CLEAN, df.ACTION_TAKEN_TARGET, test_size=.2, random_state=69)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=STOP_WORDS)),\n",
    "#     'sgd',SGDClassifier())\n",
    "    ('xgbc',xgboost.XGBClassifier(nthread=-1, n_job=4, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(pipe, df.EMAIL_TEXT_CLEAN, df.ACTION_TAKEN_TARGET, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "probs = pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, np.argmax(probs, axis=1)))\n",
    "#rinse and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skplt.metrics.plot_roc(y_test, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what some others did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "df.EMAIL_TEXT_CLEAN, df.ACTION_TAKEN_TARGET, test_size=.2,\n",
    "    random_state=69, stratify=y_train['ACTION_TAKEN_TARGET'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so instead of changing it before try changing tfidf after\n",
    "df2 = tdif.fit_transform(df['EMAIL_TEXT_CLEAN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # weighted logreg\n",
    "# # W.L.R = LogisticRegression(C=1.0, classweight='balanced, dual=False, fit_intercept=True,\n",
    "#     intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
    "#     n_jobs=-1, penalty='l2', random_state=69, solver='lbfgs', \n",
    "#     tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W.L.R.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CV Scores:\\n{}\".format(\n",
    "    cross_val_score(W.L.R, X_train, y_train, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
